{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tingfang-W/Machine-Learning/blob/main/WeightedML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aadbb2c-1ca7-4cb6-a8e9-d9fbb10fb824",
      "metadata": {
        "id": "4aadbb2c-1ca7-4cb6-a8e9-d9fbb10fb824"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries and global variables/contants\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from os import listdir\n",
        "from sklearn import metrics as mr\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# The column names in the data\n",
        "columns = ['ID', 'Clump_Thickness', 'Uniformity_of_Cell_Size', 'Uniformity_of_Cell_Shape',\n",
        "           'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin',\n",
        "           'Normal_Nucleoli', 'Mitoses', 'Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d37ee6-98dc-477c-b775-fb8ce1ef3bd2",
      "metadata": {
        "id": "c5d37ee6-98dc-477c-b775-fb8ce1ef3bd2",
        "outputId": "d1d4ee14-3c34-45a5-8b39-b97d2cf4a3bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Clump_Thickness  Uniformity_of_Cell_Size  Uniformity_of_Cell_Shape  \\\n",
            "0                5                        1                         1   \n",
            "\n",
            "   Marginal_Adhesion  Single_Epithelial_Cell_Size  Bare_Nuclei  \\\n",
            "0                  1                            2          1.0   \n",
            "\n",
            "   Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n",
            "0                3                1        1      2  \n",
            "0.6476761619190404 0.3523238380809595\n"
          ]
        }
      ],
      "source": [
        "# Common Function Definitions for Naive Bayes and Weighted Naive Bayes\n",
        "# Read the dataset\n",
        "def get_dataset():\n",
        "    dataset = pd.read_csv('breast_cancer.csv', usecols=columns)\n",
        "    dataset = dataset[dataset['Bare_Nuclei'] != '?'] # Remove the observations that has missing values\n",
        "    dataset['Bare_Nuclei'] = dataset['Bare_Nuclei'].astype(int)\n",
        "    dataset['Bare_Nuclei'] = pd.Series(list(map(int, list(dataset['Bare_Nuclei']))))\n",
        "    del dataset['ID']\n",
        "    dataset.dropna(axis=0, how='any', inplace=True)\n",
        "    return dataset\n",
        "\n",
        "# Calculate the prior probabilities of the two classes.\n",
        "def get_prior_prob(dataset):\n",
        "    y = dataset['Class']\n",
        "    total_num = len(y)\n",
        "    class2_num = len(y[y == 2])\n",
        "    class4_num = len(y[y == 4])\n",
        "    class2_prior_prob = class2_num / total_num\n",
        "    class4_prior_prob = class4_num / total_num\n",
        "    return class2_prior_prob, class4_prior_prob\n",
        "\n",
        "# Check if the functions work\n",
        "cancer_df = get_dataset()\n",
        "print(cancer_df.head(1))\n",
        "class2_prior_prob, class4_prior_prob = get_prior_prob(cancer_df)\n",
        "print(class2_prior_prob, class4_prior_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef120ff6-d569-4cda-985f-647be2cae3d1",
      "metadata": {
        "id": "ef120ff6-d569-4cda-985f-647be2cae3d1",
        "outputId": "23682c8e-1a67-4b51-fee0-1a61bdb41adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97.00171023040978\n"
          ]
        }
      ],
      "source": [
        "# Function Definitions For Naive Bayes\n",
        "\n",
        "# The probabilities of each feature given the two classes\n",
        "def get_feat_postprob(dataset, feature):\n",
        "    feature_values = list(collections.Counter(dataset[feature]))\n",
        "    feature_probs = defaultdict(list)\n",
        "    for i in range(len(feature_values)):\n",
        "        instances2 = dataset[(dataset[feature] == feature_values[i]) & (dataset['Class'] == 2)]\n",
        "        class2 = dataset[dataset['Class'] == 2]\n",
        "        if len(instances2) != 0:\n",
        "            prob2 = len(instances2) / len(class2)\n",
        "            feature_probs[feature_values[i]].append(prob2)\n",
        "        else:\n",
        "            prob2 = 1 / (len(class2) + 1)\n",
        "            feature_probs[feature_values[i]].append(prob2)\n",
        "        instances4 = dataset[(dataset[feature] == feature_values[i]) & (dataset['Class'] == 4)]\n",
        "        class4 = dataset[dataset['Class'] == 4]\n",
        "        if len(instances4) != 0:\n",
        "            prob4 = len(instances4) / len(class4)\n",
        "            feature_probs[feature_values[i]].append(prob4)\n",
        "        else:\n",
        "            prob4 = 1 / (len(class4) + 1)\n",
        "            feature_probs[feature_values[i]].append(prob4)\n",
        "    feat_postprob_df = pd.DataFrame.from_dict(feature_probs, orient='Index')\n",
        "    feat_postprob_df.reset_index(inplace=True)\n",
        "    feat_postprob_df.columns = [feature, feature + 'PostProb2', feature + 'PostProb4']\n",
        "    return feat_postprob_df\n",
        "\n",
        "# Under the conditional independence assumption, P(x_1,...x_m|y) can be calculated by the product of the posterior probabilities of each feature.\n",
        "def get_feats_postprob(dataset):\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    df_list = list()\n",
        "    for feature in features:\n",
        "        df_list.append(get_feat_postprob(dataset, feature))\n",
        "    feats_postprob_df = pd.concat(df_list, axis=1)\n",
        "    return feats_postprob_df\n",
        "\n",
        "# Calculate the posterior probabilities (numerator) of the two classes\n",
        "def get_obs_postprob(dataset, obs):\n",
        "    feats_postprob_df = get_feats_postprob(dataset)\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    posterior_prob2 = list()\n",
        "    posterior_prob4 = list()\n",
        "    for feature in features:\n",
        "        feature_prob2 = feats_postprob_df[feature + 'PostProb2'][feats_postprob_df[feature] == obs[feature]]\n",
        "        posterior_prob2.append(feature_prob2.iloc[0])\n",
        "        feature_prob4 = feats_postprob_df[feature + 'PostProb4'][feats_postprob_df[feature] == obs[feature]]\n",
        "        posterior_prob4.append(feature_prob4.iloc[0])\n",
        "    obs_postprob2 = np.multiply.accumulate(posterior_prob2)[-1]\n",
        "    obs_postprob4 = np.multiply.accumulate(posterior_prob4)[-1]\n",
        "    return obs_postprob2, obs_postprob4\n",
        "\n",
        "# Assign the label to the observation by comparing the two posterior probabilities\n",
        "def get_nbpred_label(dataset, obs):\n",
        "    postprob2, postprob4 = get_obs_postprob(dataset, obs)\n",
        "    class2_prob, class4_prob = get_prior_prob(dataset)\n",
        "    if (postprob2 * class2_prob) > (postprob4 * class4_prob):\n",
        "        pred_y = 2\n",
        "    else:\n",
        "        pred_y = 4\n",
        "    return pred_y\n",
        "\n",
        "# Calculate the average accuracy in cross-validation\n",
        "def get_nb_accuracy(fold_num):\n",
        "    x = get_dataset()\n",
        "    x = x.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    n = len(x) // fold_num\n",
        "    folds = list()\n",
        "    for i in range(fold_num - 1):\n",
        "        folds.append(x.iloc[i * n:(i + 1) * n])\n",
        "    folds.append(x.iloc[(fold_num - 1) * n: len(x)])\n",
        "    Accuracy = list()\n",
        "    for i in range(fold_num):\n",
        "        X_test = folds[i]\n",
        "        X_train = pd.concat(folds[:i] + folds[i + 1:])\n",
        "        count = 0\n",
        "        for j in range(len(X_test)):\n",
        "            predict_y = get_nbpred_label(X_train, X_test.iloc[j])\n",
        "            if predict_y == X_test.iloc[j][-1]:\n",
        "                count += 1\n",
        "        accuracy = count / (len(X_test))\n",
        "        Accuracy.append(accuracy)\n",
        "    AverageAccuracy = np.mean(Accuracy) * 100\n",
        "    return AverageAccuracy\n",
        "\n",
        "# Check if the functions work\n",
        "AverageAccuracy = get_nb_accuracy(3)\n",
        "print(AverageAccuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96183553-64f2-426f-936e-335fd21d8d1a",
      "metadata": {
        "id": "96183553-64f2-426f-936e-335fd21d8d1a",
        "outputId": "c505219c-d731-482f-b94f-c5c45766dcc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97.00171023040978\n"
          ]
        }
      ],
      "source": [
        "# Function Definitions For Weighted Naive Bayes\n",
        "\n",
        "# Get the mutual information between the class and each of the features\n",
        "def get_MI(dataset):\n",
        "    MI = dict()\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    for feature in features:\n",
        "        mi = mr.normalized_mutual_info_score(dataset['Class'], dataset[feature])\n",
        "        MI[feature] = mi\n",
        "    MI_df = pd.DataFrame.from_dict(MI, orient='index', columns=['MI'])\n",
        "    MI_df['feature'] = features\n",
        "    MI_df['Weight2'] = MI_df['MI']\n",
        "    MI_df['Weight4'] = MI_df['MI']\n",
        "    del MI_df['MI']\n",
        "    return MI_df\n",
        "\n",
        "# Get features weighted posterior probabilities\n",
        "def get_feats_wpostprob(dataset):\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    feats_postprob_df = get_feats_postprob(dataset)\n",
        "    feats_weight_df = get_MI(dataset)\n",
        "    feats_wpostprob_df = pd.DataFrame()\n",
        "    for feature in features:\n",
        "        feats_wpostprob_df[feature] = feats_postprob_df[feature]\n",
        "        feats_wpostprob_df[feature + 'WeightPostProb2'] = feats_postprob_df[feature + 'PostProb2'].values * \\\n",
        "                                                          feats_weight_df[feats_weight_df['feature'] == feature][\n",
        "                                                              'Weight2'].values\n",
        "        feats_wpostprob_df[feature + 'WeightPostProb4'] = feats_postprob_df[feature + 'PostProb4'].values * \\\n",
        "                                                          feats_weight_df[feats_weight_df['feature'] == feature][\n",
        "                                                              'Weight4'].values\n",
        "    return feats_wpostprob_df\n",
        "\n",
        "# Calculate the weighted posterior probabilities (numerator) of the two classes\n",
        "def get_obs_wnb_postprob(dataset, obs):\n",
        "    feats_wpostprob_df = get_feats_wpostprob(dataset)\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    feats_postprob2 = list()\n",
        "    feats_postprob4 = list()\n",
        "    for feature in features:\n",
        "        feature_prob2 = feats_wpostprob_df[feature + 'WeightPostProb2'][feats_wpostprob_df[feature] == obs[feature]]\n",
        "        feats_postprob2.append(feature_prob2.iloc[0])\n",
        "        feature_prob4 = feats_wpostprob_df[feature + 'WeightPostProb4'][feats_wpostprob_df[feature] == obs[feature]]\n",
        "        feats_postprob4.append(feature_prob4.iloc[0])\n",
        "    obs_postprob2 = np.multiply.accumulate(feats_postprob2)[-1]\n",
        "    obs_postprob4 = np.multiply.accumulate(feats_postprob4)[-1]\n",
        "    return obs_postprob2, obs_postprob4\n",
        "\n",
        "# Assign the label to the observation by comparing the two weighted posterior probabilities\n",
        "def get_wnb_pred_label(dataset, obs):\n",
        "    obs_postprob2, obs_postprob4 = get_obs_wnb_postprob(dataset, obs)\n",
        "    class2_prob, class4_prob = get_prior_prob(dataset)\n",
        "    if (obs_postprob2 * class2_prob) > (obs_postprob4 * class4_prob):\n",
        "        predict_y = 2\n",
        "    else:\n",
        "        predict_y = 4\n",
        "    return predict_y\n",
        "\n",
        "# Calculate the average accuracy in cross-validation\n",
        "def get_wnb_accuracy(fold_num):\n",
        "    X = get_dataset()\n",
        "    X = X.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    n = len(X) // fold_num\n",
        "    folds = list()\n",
        "    for i in range(fold_num - 1):\n",
        "        folds.append(X.iloc[i * n:(i + 1) * n])\n",
        "    folds.append(X.iloc[(fold_num - 1) * n: len(X)])\n",
        "    Accuracy = list()\n",
        "    for i in range(fold_num):\n",
        "        X_test = folds[i]\n",
        "        X_train = pd.concat(folds[:i] + folds[i + 1:])\n",
        "        count = 0\n",
        "        for j in range(len(X_test)):\n",
        "            predict_y = get_wnb_pred_label(X_train, X_test.iloc[j])\n",
        "            if predict_y == X_test.iloc[j][-1]:\n",
        "                count += 1\n",
        "        accuracy = count / (len(X_test))\n",
        "        Accuracy.append(accuracy)\n",
        "    AverageAccuracy = np.mean(Accuracy) * 100\n",
        "    return AverageAccuracy\n",
        "\n",
        "# Check if the functions work\n",
        "AverageAccuracy = get_wnb_accuracy(3)\n",
        "print(AverageAccuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ed34c11-92d2-4272-8e91-dae762c6e7d4",
      "metadata": {
        "id": "2ed34c11-92d2-4272-8e91-dae762c6e7d4",
        "outputId": "95906412-48b9-4d47-e95c-37ec84e812ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   CV  Naive Bayes  Weighted Naive Bayes\n",
            "0   3    97.001710             97.001710\n",
            "1   5    97.153996             97.153996\n",
            "2   7    97.158360             97.158360\n",
            "3   9    97.005005             97.005005\n",
            "4  10    97.164799             97.164799\n",
            "5  11    97.017187             97.017187\n"
          ]
        }
      ],
      "source": [
        "# Define the main function and calculate the accuracy for Naive Bayes and Weighted Naive Bayes\n",
        "\n",
        "# The main function\n",
        "def main():\n",
        "    fold_nums = [3, 5, 7, 9, 10, 11]\n",
        "    nb_acc = list()\n",
        "    wnb_acc = list()\n",
        "    for fold_num in fold_nums:\n",
        "        nb_acc.append(get_nb_accuracy(fold_num))\n",
        "        wnb_acc.append(get_wnb_accuracy(fold_num))\n",
        "    results_df = pd.DataFrame(list(zip(fold_nums, nb_acc, wnb_acc)),\n",
        "                              columns=['CV', 'Naive Bayes', 'Weighted Naive Bayes'])\n",
        "    return results_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cabd1a4-b717-4de4-ae9e-663338d81d5a",
      "metadata": {
        "id": "6cabd1a4-b717-4de4-ae9e-663338d81d5a",
        "outputId": "7849a048-800c-414a-ae15-865377752744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 2, 2, 2, 2]\n",
            "[[0.44444444 0.         0.         0.         0.11111111 0.\n",
            "  0.22222222 0.         0.        ]\n",
            " [0.44444444 0.33333333 0.33333333 0.44444444 0.66666667 1.\n",
            "  0.22222222 0.11111111 0.        ]\n",
            " [0.22222222 0.         0.         0.         0.11111111 0.11111111\n",
            "  0.22222222 0.         0.        ]\n",
            " [0.55555556 0.77777778 0.77777778 0.         0.22222222 0.33333333\n",
            "  0.22222222 0.66666667 0.        ]\n",
            " [0.33333333 0.         0.         0.22222222 0.11111111 0.\n",
            "  0.22222222 0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Define Common functions for KNN and weighted KNN\n",
        "\n",
        "# Read the dataset\n",
        "def get_data():\n",
        "    dataset = pd.read_csv('breast_cancer.csv', usecols=columns)\n",
        "    dataset = dataset[dataset['Bare_Nuclei'] != '?']\n",
        "    dataset['Bare_Nuclei'] = pd.Series(list(map(int, list(dataset['Bare_Nuclei']))))\n",
        "    del dataset['ID']\n",
        "    dataset.dropna(axis=0, how='any', inplace=True)\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    x = dataset[features]\n",
        "    x = np.array(x)\n",
        "    y = dataset['Class']\n",
        "    y = list(y)\n",
        "    return dataset, x, y\n",
        "\n",
        "# Normalize the features\n",
        "def get_std_data(x):\n",
        "    minVals = x.min(0)\n",
        "    maxVals = x.max(0)\n",
        "    ranges = maxVals - minVals\n",
        "    stdx = np.zeros(np.shape(x))\n",
        "    m = x.shape[0]\n",
        "    stdx = x - np.tile(minVals, (m, 1))\n",
        "    stdx = stdx / np.tile(ranges, (m, 1))  # element wise divide\n",
        "    return stdx\n",
        "\n",
        "# Check if the functions work\n",
        "dataset, x, y = get_data()  # load data setfrom file\n",
        "print(y[:5])\n",
        "stdx = get_std_data(x)\n",
        "print(stdx[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f103b7ab-7551-4758-94ce-08b359f3aca2",
      "metadata": {
        "id": "f103b7ab-7551-4758-94ce-08b359f3aca2",
        "outputId": "86a0d4da-c97b-4579-a8c4-ffab075a1330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88.28828828828829\n"
          ]
        }
      ],
      "source": [
        "# Define functions for KNN\n",
        "\n",
        "# Get the labels of each observation\n",
        "def get_knn_pred_label(inX, dataset, labels, k):\n",
        "    datasetSize = dataset.shape[0]\n",
        "    diffMat = np.tile(inX, (datasetSize, 1)) - dataset\n",
        "    sqDiffMat = diffMat ** 2\n",
        "    sqDistances = sqDiffMat.sum(axis=1)\n",
        "    distances = sqDistances ** 0.5\n",
        "    sortedDistIndicies = distances.argsort()\n",
        "    classCount = {}\n",
        "    for i in range(k):\n",
        "        voteLabel = labels[sortedDistIndicies[i]]\n",
        "        classCount[voteLabel] = classCount.get(voteLabel, 0) + 1\n",
        "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    return sortedClassCount[0][0]\n",
        "\n",
        "# Perform KNN and calculate the accuracy\n",
        "def KNN(k):\n",
        "    ratio = 0.50  # hold out 50% of the data as the test set\n",
        "    dataset, x, y = get_data()  # load data set from file\n",
        "    stdx = get_std_data(x)\n",
        "    m = stdx.shape[0]\n",
        "    test_size = int(m * ratio)\n",
        "    errorCount = 0.0\n",
        "    for i in range(test_size):\n",
        "        pred_label = get_knn_pred_label(stdx[i, :], stdx[test_size:m, :], y[test_size:m], k)\n",
        "        if pred_label != y[i]: errorCount += 1.0\n",
        "    accuracy = (1 - (errorCount / float(test_size))) * 100\n",
        "    return accuracy\n",
        "\n",
        "# Check if the functions work\n",
        "accuracy = KNN(1)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557e2f73-c903-4801-842e-db12b68b083f",
      "metadata": {
        "id": "557e2f73-c903-4801-842e-db12b68b083f",
        "outputId": "11d9abf7-af15-410d-bdec-5bea1b6e5a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90.990990990991\n"
          ]
        }
      ],
      "source": [
        "# Define functions for weighted KNN\n",
        "\n",
        "# Get the mutual information\n",
        "def get_MI(dataset):\n",
        "    MI = dict()\n",
        "    features = [col for col in columns if col not in ['ID', 'Class']]\n",
        "    for feature in features:\n",
        "        mi = mr.normalized_mutual_info_score(dataset['Class'], dataset[feature])\n",
        "        MI[feature] = mi\n",
        "    MI_df = pd.DataFrame.from_dict(MI, orient='index', columns=['MI'])\n",
        "    MI_df['feature'] = features\n",
        "    MI_df['Weight'] = MI_df['MI']\n",
        "    del MI_df['MI']\n",
        "    weights = np.array(MI_df['Weight'])\n",
        "    return weights\n",
        "\n",
        "# Get the label of each observation\n",
        "def get_wknn_pred_label(inX, dataset, x, y, k):\n",
        "    weights = get_MI(dataset)\n",
        "    xSize = x.shape[0]\n",
        "    diffMat = np.tile(inX, (xSize, 1)) - x\n",
        "    sqDiffMat = weights * diffMat ** 2\n",
        "    sqDistances = sqDiffMat.sum(axis=1)\n",
        "    distances = sqDistances ** 0.5\n",
        "    sortedDistIndicies = distances.argsort()\n",
        "    classCount = {}\n",
        "    for i in range(k):\n",
        "        voteLabel = y[sortedDistIndicies[i]]\n",
        "        classCount[voteLabel] = classCount.get(voteLabel, 0) + 1\n",
        "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    return sortedClassCount[0][0]\n",
        "\n",
        "# Perform weighted KNN and calculate the accuracy\n",
        "def weighted_KNN(k):\n",
        "    ratio = 0.50  # hold out 50% of the data as the test set\n",
        "    dataset, x, y = get_data()  # load data from file\n",
        "    m = stdx.shape[0]\n",
        "    test_size = int(m * ratio)\n",
        "    errorCount = 0.0\n",
        "    for i in range(test_size):\n",
        "        pred_label = get_wknn_pred_label(stdx[i, :], dataset, stdx[test_size:m, :], y[test_size:m], k)\n",
        "        if (pred_label != y[i]): errorCount += 1.0\n",
        "    accuracy = (1 - (errorCount / float(test_size))) * 100\n",
        "    return accuracy\n",
        "\n",
        "# Check if the functions work\n",
        "accuracy = weighted_KNN(1)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "569ce589-6837-4c69-a952-697e867183e0",
      "metadata": {
        "id": "569ce589-6837-4c69-a952-697e867183e0",
        "outputId": "d1fae7fe-5506-4148-b9cf-6136d9023545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   K        KNN  Weighted KNN\n",
            "0  1  88.288288     90.990991\n",
            "1  3  89.489489     92.492492\n",
            "2  5  90.390390     92.192192\n",
            "3  7  90.390390     91.891892\n",
            "4  9  89.789790     91.891892\n"
          ]
        }
      ],
      "source": [
        "# Get the accuracy for different values of K\n",
        "def main():\n",
        "    k_values = [1, 3, 5, 7, 9]\n",
        "    knn_acc = list()\n",
        "    wknn_acc = list()\n",
        "    for k in k_values:\n",
        "        knn_acc.append(KNN(k))\n",
        "        wknn_acc.append(weighted_KNN(k))\n",
        "    results_df = pd.DataFrame(list(zip(k_values, knn_acc, wknn_acc)),\n",
        "                              columns=['K', 'KNN', 'Weighted KNN'])\n",
        "    return results_df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf24b31-9c4c-4b93-96e2-fc955c6484ed",
      "metadata": {
        "id": "1cf24b31-9c4c-4b93-96e2-fc955c6484ed"
      },
      "outputs": [],
      "source": [
        "# Define functions for logistic regression and weighted logistic regression\n",
        "\n",
        "# Add weights to the features by taking the power of each feature with the corresponding mutual information\n",
        "def apply_weights_as_powers(X, weights):\n",
        "    powered_X = X ** weights.reshape(1, -1)\n",
        "    return powered_X\n",
        "\n",
        "# Define the model parameters\n",
        "def train_logistic_regression(X_train, y_train):\n",
        "    lr = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs', penalty=None)\n",
        "    lr.fit(X_train, y_train)\n",
        "    return lr\n",
        "\n",
        "# Calculate the average accuracy in cross-validation\n",
        "def get_accuracy_lr(dataset, X, y, k_values):\n",
        "    results = []\n",
        "    y = np.array(y)\n",
        "\n",
        "    weights = get_MI(dataset)\n",
        "    powered_X = apply_weights_as_powers(X, weights)\n",
        "\n",
        "    for k in k_values:\n",
        "        kf = KFold(n_splits=k)\n",
        "        fold_accuracies_lr = []\n",
        "        fold_accuracies_weighted_lr = []\n",
        "\n",
        "        for train_index, test_index in kf.split(X):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            X_train_w, X_test_w = powered_X[train_index], powered_X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]  # Correct indexing for y\n",
        "\n",
        "            # Train logistic regression without weights\n",
        "            lr = train_logistic_regression(X_train, y_train)\n",
        "            y_pred_lr = lr.predict(X_test)\n",
        "            accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "            fold_accuracies_lr.append(accuracy_lr)\n",
        "\n",
        "            # Train the weighted  logistic regression\n",
        "            lr_w = train_logistic_regression(X_train_w, y_train)\n",
        "            y_pred_lr_w = lr_w.predict(X_test_w)\n",
        "            accuracy_lr_w = accuracy_score(y_test, y_pred_lr_w)\n",
        "            fold_accuracies_weighted_lr.append(accuracy_lr_w)\n",
        "\n",
        "        results.append({\n",
        "            'K': k,\n",
        "            'Logistic Regression': np.mean(fold_accuracies_lr) * 100,\n",
        "            'Weighted Logistic Regression': np.mean(fold_accuracies_weighted_lr)* 100\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407e4302-048a-4356-902c-afe6939580df",
      "metadata": {
        "id": "407e4302-048a-4356-902c-afe6939580df",
        "outputId": "0426b401-57ae-4047-fd09-59a8eb4907aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    K  Logistic Regression  Weighted Logistic Regression\n",
            "0   3            95.355445                     95.354772\n",
            "1   5            95.361912                     96.407811\n",
            "2   7            95.809837                     95.957080\n",
            "3   9            96.258258                     96.404404\n",
            "4  10            95.811850                     96.411126\n",
            "5  11            95.814704                     96.413313\n"
          ]
        }
      ],
      "source": [
        "# Get the accuracy for logistic regression and weighted logistic regression in cross-validation\n",
        "def main():\n",
        "    k_values = [3, 5, 7, 9, 10, 11]\n",
        "    dataset, X, y = get_data()\n",
        "    cv_results_lr = get_accuracy_lr(dataset, X, y, k_values)\n",
        "    return cv_results_lr\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(main())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}